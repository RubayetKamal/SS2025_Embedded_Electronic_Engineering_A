\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{references.bib}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[hidelinks]{hyperref}


\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  breaklines=true,
  frame=single,
}


\lstset{
  language=C,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{green!60!black},
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{gray!10},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  frame=single,
  tabsize=2,
  captionpos=b,
  breaklines=true,
  breakatwhitespace=false,
  escapeinside={(*@}{@*)}
}



\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Partition-based scheduling on multi-core systems\\
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Rubayet Kamal}
\IEEEauthorblockA{\textit{Electronic Engineering} \\
\textit{Hochschule Hamm-Lippstadt}\\
Lippstadt, Germany\\
rubayet.kamal@stud.hshl.de}
}

\maketitle

\begin{abstract}
Systems with components of varying criticality often require stronger verification for high-criticality parts compared to low-criticality ones. In multi-core systems, partitioning reduces the complexity of scheduling by assigning partitions to different cores, allowing isolated execution with optional inter-partition communication. However, partitioned scheduling faces resource utilization challenges similar to the bin-packing problem: tasks may fail to be assigned to any processor even when sufficient total capacity exists. This inefficiency is particularly severe when tasks have high individual utilization, potentially limiting system resource usage to as little as half. Moreover, assigning tasks while maintaining load balance and predictability is an NP-hard problem. This paper explores the fundamentals of partition-based scheduling and examines heuristic allocation and scheduling algorithms. In \cite{AbdallahGB24}, the authors have used a clustering-based task allocation strategy with Earlest Deadline First (EDF) scheduling algorithm in each core. This strategy or technique is simulated using C and allocation of tasks are visualised using Python script.


% The study focuses on the clustering-based task allocation strategy implemented in \cite{b1}, which uses the Earliest Deadline First (EDF) scheduling algorithm to ensure that the utilization factor remains less than 1 and communication cost between cores is minimized. A simulation written in C based on the strategy implemented in \cite{b1} is done to visualise the distribution of tasks among different homoegenous cores. 
% Furthermore, work done in \cite{b2} has extended partitioned EDF scheduling by incorporating Quality of Service (QoS) constraints, allowing tasks to occasionally skip instances in order to handle overload and energy constraints more flexibly. This QoS-aware approach enhances the robustness of partitioned scheduling by improving schedulability in multicore systems while minimizing energy consumption.
\end{abstract}

\begin{IEEEkeywords}
multi-core, partition, EDF, styling, insert
\end{IEEEkeywords}

\section{Introduction}
Real-time systems are often classified based on their timing requirements into soft, firm, and hard real-time systems \cite{6122386}.  Real-time computer system must react to stimuli from its environment within time intervals dictated by its environment. The instant when a result must be produced is called a deadline. If a result has utility even after the deadline has passed, the deadline is classified as soft, otherwise it is firm. If severe consequences could result if a firm deadline is missed, the deadline is called hard \cite{kopetzDist}. Firm real-time systems are often referred to as mixed-criticality systems due to the presence of some tasks being highly critical than others \cite{zamora2013}.

The development of mixed-criticality real-time systems presents several challenges, particularly in task scheduling and resource allocation. While power management techniques such as Dynamic Voltage and Frequency Scaling (DVFS) and Dynamic Power Management (DPM) have been explored for energy optimization, these methods were initially designed for uniprocessor systems \cite{6122386}. With the increasing computational demands and advances in integrated circuit miniaturization, multi-core platforms is a valid solution for providing the necessary computational resources.

Scheduling tasks on multi-core systems introduces two key problems \cite{AbdallahGB24}:
\begin{itemize}
    \item \textbf{Allocation problem (spatial organization)} : assigning each task to a core.
    \item \textbf{Scheduling problem (temporal organization)} : determining the execution order of tasks on each core.
\end{itemize}

According to~\cite{7832222}, task scheduling heavily depends on efficient task allocation. A clustering-based scheduling algorithm addresses this by partitioning tasks that frequently communicate onto the same or nearby cores, minimizing communication overhead \cite{AbdallahGB24}. As per~\cite{zamora2013}, partitioning isolates different parts of the system to prevent mutual interference. However, partitioned scheduling faces resource utilization issues similar to the bin-packing problem: a task might not fit on any core despite sufficient total system capacity. This inefficiency becomes significant when individual task utilizations are high, and in the worst case, only half of the system’s resources may be utilized.

To address this, semi-partitioned scheduling (a hybrid approach) has been proposed. In this method, most tasks are statically assigned to fixed cores, while a small number of tasks are split into subtasks across different cores, enabling limited task migration \cite{AbdallahGB24}. Each core must still pass schedulability tests after assignment. Clustering concepts are used to group communicating tasks together, and in \cite{AbdallahGB24}, the author employed Earliest Deadline First (EDF) algorithm for local scheduling of each core.

EDF is
a scheduling algorithm in which jobs with earliest deadlines have higher
priority. EDF is an optimal scheduling algorithm on preemp-
tive uniprocessors, in the following sense: if a collection of
independent jobs can be scheduled (by any algorithm) such
that all the jobs complete by their deadlines, EDF will schedule
this collection of jobs such that they all complete by their
deadlines \cite{6122386}.

Although semi-partitioned scheduling shows theoretical performance improvements, its practical adoption remains limited due to concerns about context switch overhead and migration costs. As discussed in~\cite{5953668}, experiments suggest that for task sets with reasonable parameters, semi-partitioned scheduling can indeed outperform traditional partitioned approaches even under realistic overhead conditions.

% While low-power scheduling on heterogeneous cores is a known NP-complete problem~\cite{7832222}, this paper focuses on homogeneous cores, where task allocation remains NP-hard. 

A clustering-based task allocation strategy that aims to minimize communication costs, balance load across cores, and improve system feasibility for mixed-criticality real-time systems is implemented in this paper, inspired from \cite{AbdallahGB24}. Each cores run on Earliest deadline first scheduling algorithm. However, \cite{5194980} has suggested that EDF can lead to many tasks missing their deadlines on multi-core processors in
overload condition for multi-core systems. The purpose of this paper is to evaluate the communication cost between core and ease of allocation of tasks using the clustering-based strategy. 

The remainder of this paper is structured as follows: 
Section~\ref{sec:fundamentals} presents the core concepts required for understanding real-time mixed critical systems along with multi-core architectures and multi-core scheduling strategies.
Section~\ref{sec: partition-based scheduling} defines partition-based scheduling mechanisms, highlighting the differences between static and dynamic partitioning, and discussing the objectives and challenges associated with partitioning. The importance of task partitioning in mixed-criticality systems is also discussed. 
Section~\ref{sec: clustering-based scheduling} outlines the clustering-based scheduling strategy and task allocation methodology, as originally proposed in~\cite{AbdallahGB24}.
Section~\ref{sec:implementation} describes the implementation of the named algorithm using C code snippets. Thereafter, section \ref{sec: simulation and outcome} shows the outcome from simulation and discusses the key findings. 
Finally, Section~\ref{subsec: conclusion} concludes the paper and summarizes the main contributions.




\section{Background Material}
\label{sec:fundamentals}
Before exploring the strategy implemented in this paper, it is necessary to discuss the fundamental concepts to ensure that the terms used in later sections are familiar. This section is divided into three subsections: \ref{subsec:task and task types} introduces real-time systems and tasks; \ref{subsec: architecture of multi-core processors} covers multi-core processor architectures; and \ref{subsec: scheduling approach on multicore architecture} explains scheduling approaches on multi-core systems. The objective of this section is to clarify all necessary terminology before implementing and simulating the desired partition-based scheduling algorithm.

\subsection{Tasks and Task Types in Real-Time Systems}
\label{subsec:task and task types}
A real-time system evolves as a function of physical time~\cite{kopetzDist}. A set of related jobs that execute to support a system function is called a task~\cite{9999}. Therefore, a real-time task is primarily defined by its temporal properties.

According to~\cite{5465974}, a periodic task $\tau_i$ is characterized by two parameters:
\begin{itemize}
    \item \textbf{Worst-Case Execution Time (WCET) $W_i$}: The maximum amount of time a task $\tau_i$ could take to execute.
    \item \textbf{Period $T_i$}: The fixed time interval between successive arrivals of the task.
\end{itemize}
These properties are assumed to be constant for all task instances in a homogeneous multi-core architecture.

Additional temporal characteristics of real-time tasks, as listed in~\cite{AbdallahGB24}, include:
\begin{itemize}
    \item \textbf{Release Time or Arrival Time ($R_i$)}: The time at which a task $\tau_i$ becomes eligible to start execution.
    \item \textbf{Deadline ($D_i$)}: The latest time by which the task must complete its execution.
    \item \textbf{Latency ($L_i$)}: The remaining time before a task either starts execution or its deadline occurs.
    \item \textbf{Laxity or Slack Time ($X_i$)}: The maximum time a task can be delayed after activation and still meet its deadline.
\end{itemize}

Figure~\ref{fig:temporal_properties_of_task} illustrates the temporal properties of a real-time task.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{Temporal properties of task.png}
    \caption{Temporal properties of a task}
    \label{fig:temporal_properties_of_task}
\end{figure}

Real-time tasks can be classified as either \textit{periodic} or \textit{aperiodic}:
\begin{itemize}
    \item \textbf{Periodic Tasks}: These tasks consist of an infinite sequence of identical activities, called instances or jobs, that are activated regularly at a constant rate~\cite{butazo99}. Periodic tasks are characterized by strict deadlines and form the majority of tasks in a real-time application. According to~\cite{french18}, a periodic task $\tau_i$ is typically modeled by four parameters: $(R_i, W_i, D_i, P_i)$~\cite{AbdallahGB24}.
    
    \item \textbf{Aperiodic Tasks}: These tasks also consist of a sequence of identical jobs, but their activations are unpredictable and not evenly spaced. Aperiodic tasks are generally modeled by a single parameter, $W_i$, representing their worst-case execution time~\cite{AbdallahGB24}.
\end{itemize}

A special class of aperiodic tasks is \textit{sporadic tasks}~\cite{butazo99}. Sporadic tasks, while aperiodic in execution time, have their execution rate constrained by a minimum inter-arrival time. They are modeled by the parameters $(W_i, D_i, T_{\text{min}})$, where $T_{\text{min}}$ is the minimum time interval between two consecutive activations, and $D_i$ is the critical delay~\cite{AbdallahGB24}.




\subsection{Architecture of Multi-Core Processors}
\label{subsec: architecture of multi-core processors}

The performance of single-threaded processors has become increasingly limited by power constraints, prompting processor architects to adopt multi-core designs as a means to enhance performance. As Intel analyst Nathan stated, "multi-core processors are the inevitable product of Moore's Law." The growing demands of modern applications and the continued advancement of CPU manufacturing technologies—enabling the integration of a large number of transistors on a single chip—have driven the rapid development of multi-core processors~\cite{6234619}.

Although multi-core technology is a hardware innovation, it requires corresponding software support to fully realize its potential. In essence, a multi-core processor integrates multiple processing cores on a single chip, allowing the system to leverage the abundance of transistor resources. This enables the exploitation of various levels of parallelism—such as instruction-level and thread-level parallelism—through concurrent core execution, thereby enhancing overall performance~\cite{6234619}.

Increasing the number of cores in a processor not only improves parallel task execution but also enhances energy efficiency. Multi-core systems can deliver higher performance by using several low-frequency cores instead of a single high-frequency core, offering both flexibility and power savings.

Compared to single-core processors, multi-core processors offer several key advantages:
\begin{itemize}
    \item Improved parallel performance~\cite{h2000},
    \item Lower communication latency~\cite{lx2015},
    \item Higher bandwidth~\cite{997877},
    \item Reduced power consumption.
\end{itemize}

Multi-core processors can be categorized as either \textit{homogeneous} or \textit{heterogeneous}, depending on how the cores are integrated:
\begin{itemize}
    \item \textbf{Homogeneous Multi-Core Processors}: These integrate multiple identical cores on a single chip. Each core typically performs similar tasks, enabling symmetric and balanced parallel computing.
    \item \textbf{Heterogeneous Multi-Core Processors}: These integrate a mix of cores with varying complexity. Typically, a complex superscalar core (main core) handles general-purpose computation, such as operating system tasks and scheduling, while simpler subordinate cores are optimized for specific tasks. These lightweight cores are often managed by the main core and accelerate computations for specialized applications~\cite{6234619}.
\end{itemize}



\subsection{The scheduling concept}
\label{subsec: scheduling approach on multicore architecture}
When a single processor has to execute a set of concurrent tasks – that is, tasks that can overlap in time – the CPU has to be assigned to the various tasks according to a predefined criterion, called a scheduling policy. The set of rules that, at any time, determines the order in which tasks are executed is called a scheduling algorithm \cite{butazo99}.

In many operating systems that allow dynamic task activation, the running task can be interrupted at any point, so that a more important task that arrives in the system can immediately gain the processor and does not need to wait in the ready queue. In this case, the running task is interrupted and inserted in the ready queue, while the CPU is assigned to the most important ready task that just arrived. The operation of suspending the running task and inserting it into the ready queue is called preemption as shown in fig. \ref{fig:preemption}  \cite{butazo99}. Preemptive scheduling typically allows higher efficiency, in the sense that it al-
lows executing a real-time task sets with higher processor utilization \cite{butazo99}.

"Among the great variety of algorithms proposed for scheduling real-time tasks, the following main classes can be identified:
\begin{itemize}
    \item Preemptive: In preemptive algorithms, the running task can be interrupted at any time to assign the processor to another active task, according to a predefined scheduling policy.
    \item Non-preemtptive: In non-preemptive algorithms, a task, once started, is executed by the pro- cessor until completion. In this case, all scheduling decisions are taken as the task terminates its execution.
    \item Static: Static algorithms are those in which scheduling decisions are based on fixed parameters, assigned to tasks before their activation.
    \item Dynamic: Dynamic algorithms are those in which scheduling decisions are based on dynamic parameters that may change during system evolution.
    \item Off-line: A scheduling algorithm is used off line if it is executed on the entire task set before tasks activation. The schedule generated in this way is stored in a table and later executed by a dispatcher.
    \item Online: A scheduling algorithm is used online if scheduling decisions are taken at runtime every time a new task enters the system or when a running task terminates.
    \item Optimal: An algorithm is said to be optimal if it minimizes some given cost function defined over the task set. When no cost function is defined and the only concern is to achieve a feasible schedule, then an algorithm is said to be optimal if it is able to find a feasible schedule, if one exists.
    \item Heuristic: An algorithm is said to be heuristic if it is guided by a heuristic function in taking its scheduling decisions. A heuristic algorithm tends toward the optimal schedule, but does not guarantee finding it" \cite{butazo99}.
\end{itemize}

Multi-core scheduling is a 2 dimensional problem. First, allocation problem (spatial organization) deter- mines for each tasks which core should run on. Second, scheduling problem (temporal organization) de- fines date and order execution of tasks \cite{AbdallahGB24}.

% The complexity of scheduling algorithms is of high relevance in dynamic real- time systems, where scheduling decisions must be taken on line during task execution. A polynomial algorithm is one whose time complexity grows as a polynomial function p of the input length n of an instance. The complexity of such algorithms is denoted by O(p(n)). Each algorithm whose complexity function cannot be bounded in that way is called an exponential time algorithm. In particular, NP is the class of all decision problems that can be solved in polynomial time by a nondeterministic Turing machine. According to \cite{butazo99}: "A problem Q is said to be NP-complete if Q ∈ NP and, for every Q′ ∈ NP, Q’ is polynomially transformable to Q. A decision problem Q is said to be NP-hard if all problems in NP are polynomially transformable to Q, but we cannot show that Q ∈ NP."

The complexity of scheduling algorithms is of high relevance in dynamic real-time systems, where scheduling decisions must be taken online during task execution. A polynomial algorithm is one whose time complexity grows as a polynomial function $p$ of the input length $n$ of an instance. The complexity of such algorithms is denoted by $\mathcal{O}(p(n))$. Each algorithm whose complexity function cannot be bounded in that way is called an exponential time algorithm.

In particular, $\mathsf{NP}$ is the class of all decision problems that can be solved in polynomial time by a nondeterministic Turing machine. According to \cite{butazo99}:

\begin{quote}
"A problem $Q$ is said to be $\mathsf{NP}$-complete if $Q \in \mathsf{NP}$ and, for every $Q' \in \mathsf{NP}$, $Q'$ is polynomially transformable to $Q$. A decision problem $Q$ is said to be $\mathsf{NP}$-hard if all problems in $\mathsf{NP}$ are polynomially transformable to $Q$, but we cannot show that $Q \in \mathsf{NP}$."
\end{quote}


An algorithm is said to be heuristic if it is guided by a heuristic function in taking its scheduling decisions. A heuristic algorithm tends toward the optimal schedule, but does not guarantee finding it. For task scheduling, heuristic-based scheduling algorithms are common. These are usually classified into three classes:

\begin{itemize}
    \item "Priority-based scheduling: priorities are calculated and assigned to the tasks which are then scheduled on the processors according to their priorities.
    \item Duplication-based scheduling: while tasks are allocated to a processor, its parent (and predecessor) tasks are duplicated to occupy the idle times of the processor to eliminate the communication delay that occurs when message is passed from the parent tasks to the allotted task.
    \item In cluster-based scheduling, some tasks, that need to communicate among themselves, are grouped together to form a cluster. Clusters are then scheduled on to an available processor. The main problem arises when the number of clusters is greater than the number of processors. This leads to programming the communicating clusters on the same processor and which remains in the nearest processor" \cite{AbdallahGB24}.
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1.2\linewidth]{preemption.png}
    \caption{preemption}
    \label{fig:preemption}
\end{figure}


\section{Partition-based Scheduling}
\label{sec: partition-based scheduling}

Various algorithms for scheduling recurrent real-time task systems on multiprocessor platforms impose different constraints on where a task's jobs may execute. Two fundamental approaches widely studied for scheduling on multi-core processors are \textit{global scheduling} and \textit{partition-based scheduling}:

\begin{itemize}
    \item \textbf{Global Scheduling:} In global scheduling, a task may execute on any processor core and is allowed to migrate between cores. A single global ready queue holds all ready jobs, and at each scheduling decision point, the highest-priority job is selected for execution. Essentially, a unified scheduling policy is applied across all cores. This concept is illustrated in Fig.~\ref{fig:global scheduling}.
    
    \item \textbf{Partition-based Scheduling:} In partitioned scheduling, tasks are statically assigned to specific cores. Each processor core schedules only the tasks assigned to it using a local uniprocessor scheduling algorithm. Hence, every task is strictly bound to a single core, and all its jobs must execute on that core. The goal is to assign each task either individually or as part of a subset to a particular core. This enables the application of uniprocessor scheduling techniques independently on each core, each maintaining its own task queue~\cite{AbdallahGB24}. This approach is shown in Fig.~\ref{fig:partitioning scheduling}.
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{Global Scheduling.png}
    \caption{Global scheduling \cite{AbdallahGB24}}
    \label{fig:global scheduling}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{Partitioning Scheduling.png}
    \caption{Partition-based scheduling \cite{AbdallahGB24}}
    \label{fig:partitioning scheduling }
\end{figure}

Global scheduling allows optimal task distribution due to migration flexibility. However, implementing efficient and predictable global schedulers for real-time systems has proven challenging. Notably, unlike partitioned scheduling—where the synchronous task arrival pattern represents the worst-case scenario—global scheduling lacks any known finite set of worst-case job arrival sequences. This significantly complicates exact schedulability analysis. As demonstrated in~\cite{sbmbgb}, there exists no optimal online algorithm for global scheduling of constrained-deadline sporadic task systems on two or more processors.

The task allocation problem in partition-based scheduling is equivalent to the well-known \textit{bin-packing} problem, where one must assign $n$ items of varying sizes into $m$ identical bins, a problem known to be NP-hard.

Both global and partitioned scheduling are special cases of \textit{clustered scheduling}, as discussed in Section~\ref{subsec: scheduling approach on multicore architecture}. In clustered scheduling, the processor cores are grouped into clusters, and each recurrent task is statically mapped to one cluster. Migration of a task’s jobs is only permitted within the assigned cluster~\cite{sbmbgb}.

Recent research suggests that the partitioned approach outperforms others when it comes to scheduling hard real-time systems—both theoretically and practically. However, it is not without drawbacks. Partitioning can lead to significant resource underutilization: even when the system has enough total capacity, a task might not fit on any individual core. This issue is exacerbated when task utilization is high, potentially restricting system utilization to as little as 50\% in the worst case.

To mitigate this, a \textit{hybrid} or \textit{semi-partitioned} scheduling approach has been proposed. Here, tasks are first allocated via a partitioning heuristic, but selective task migrations are allowed across cores. Cores may exchange some tasks with others—a mechanism referred to as task migration. This enhances flexibility and helps better utilize processor capacity. A semi-partitioned scheduling algorithm consists of two parts: the partitioning algorithm, which determines how to split and assign each task (or rather each part of it) to a fixed processor, and the scheduling algorithm, which determines how to schedule the tasks assigned to each processor \cite{5953668}.



It is important to note that for global, partitioned, and hybrid approaches, certain schedulability conditions must be satisfied. These will be discussed in Section~\ref{sec: clustering-based scheduling}.

In~\cite{AbdallahGB24}, a development strategy based on the hybrid approach is proposed, as it reduces communication overhead and energy consumption. Consequently, this results in a feasible and efficient system with improved quality of service. This clustering-based scheduling strategy is further elaborated in Section~\ref{sec: clustering-based scheduling}.


\section{Clustering-Based Scheduling Strategy}
\label{sec: clustering-based scheduling}

In~\cite{AbdallahGB24}, it is assumed that each core schedules tasks locally using the EDF (Earliest Deadline First) algorithm. This section presents the clustering-based task allocation strategy implemented in~\cite{AbdallahGB24}. It is divided into three subsections: the utilization factor in~\ref{subsec: utlization factor}, the communication cost between cores due to their distances in~\ref{communication cost}, and the proposed scheduling strategy in~\ref{subsec: proposed strategy}.

\subsection{Utilization Factor}
\label{subsec: utlization factor}

According to Liu and Layland~\cite{Fisher2016}, the processor utilization rate by a task $\tau_i$ is given by:

\begin{equation}
    \upsilon_{\tau_i} = \frac{w_i}{T_i}
   \label{eq:ut}
\end{equation}

Here, $w_i$ represents the worst-case execution time of task $\tau_i$, and $T_i$ is its period. The utilization factor for $N$ tasks assigned to core $C_k$ is the sum of the individual utilizations:

\begin{equation}
   U_{C_k} = \sum_{i=1}^{N} \upsilon_{\tau_i} = \sum_{i=1}^{N} \frac{w_i}{T_i}, \quad \forall k \in [1 \ldots P]
   \label{eq:utN}
\end{equation}

A necessary condition for schedulability of tasks on a core is that the total utilization does not exceed 1:

\begin{equation}
U_{C_k} \leq 1
\label{eq:utilization_constraint}
\end{equation}

In~\cite{AbdallahGB24}, each core $C_k \ (k \in [1 \ldots P])$ schedules its assigned tasks locally using EDF. Each core must satisfy the schedulability condition defined in Equation~\ref{eq:utilization_constraint}.

\subsection{Communication Cost}
\label{communication cost}

Communication between cores is facilitated by a communication medium such as a bus or a Network-on-Chip (NoC). In NoC architectures, the communication cost between a pair of cores $C_k$ and $C_l$ depends on their relative distance and is denoted by $\text{Cost}_{C_k,C_l}$. Let $X_{C_k,C_l}$ be the cost of transferring one byte of data from core $C_k$ to core $C_l$. The cost matrix is defined as:

\begin{equation}
\text{Cost}_{C_k, C_l} =
\begin{cases}
X_{C_k, C_l}, & \text{if } k \ne l,\quad \forall k, l \in [1 \ldots P] \\
0, & \text{otherwise}
\end{cases}
\label{eq:cost_function}
\end{equation}

The total communication cost is obtained by multiplying $\text{Cost}_{C_k,C_l}$ with the volume of exchanged data, denoted by $SM_{i,j}$, which represents the size of the message exchanged between tasks $\tau_i$ and $\tau_j$ in bytes:

\begin{equation}
\text{TotalCost} = \sum_{k=1}^{P} \sum_{l=1}^{P} \sum_{i=1}^{N} \sum_{j=1}^{N} \text{Cost}_{C_k, C_l} \cdot SM_{i,j}
\label{eq:total_cost}
\end{equation}

\subsection{Proposed Strategy}
\label{subsec: proposed strategy}

The clustering-based allocation strategy builds on the concept introduced in Section~\ref{subsec: scheduling approach on multicore architecture}. The key idea is to group communicating tasks into clusters (CL) and assign them to the same or neighboring cores to reduce communication overhead. Each core schedules its assigned tasks locally using EDF and must satisfy the schedulability condition from Equation~\ref{eq:utilization_constraint}.

Tasks that frequently communicate are grouped into clusters and allocated to the least loaded core to balance the load and improve system performance. This ensures that the load on each core does not exceed its maximum capacity, maintaining system reliability and real-time performance.

In real-time systems, task dependencies and inter-task communication are critical. When tasks are distributed across different cores, minimizing communication cost becomes essential to maintaining system performance.

The objective of the strategy is to allocate tasks to cores such that total communication cost is minimized while satisfying the utilization constraint. In~\cite{AbdallahGB24}, the proposed strategy is compared with the approaches in~\cite{thatindianpaper} and~\cite{anotherindianpaper}. The system uses a 1-D Mesh network as the communication topology, where cores are connected in a linear array. Each core communicates only with its immediate neighbors.

For example, if Task A resides on Core 0 and needs to communicate with Task B on Core 3, the message must traverse through Core 1 and Core 2—resulting in three hops. To reduce such communication delays, the strategy allocates frequently communicating tasks to the same or nearby cores.

Clusters of tasks are mapped to specific cores that are close to each other in the mesh network. Section~\ref{sec:implementation} will detail the implementation of this strategy in C and present simulation results obtained using UPPAAL.


\section{Implementation of Clustering-based algorithm in C}
\label{sec:implementation}

The complete working code of the implementation can be found in the following GitHub repository:  
\href{https://github.com/RubayetKamal/SS2025_Embedded_Engineering/tree/main/Real%20Time%20Systems/PartitionBasedScheduling_In_MulticoreSystems}{github.com/RubayetKamal/SS2025\_Embedded\_Engineering}. This section is divided into 5 subsections where subsection \ref{subsec: clustering} introduces the algorithm used to implement clustering for task allocation used by \cite{AbdallahGB24}. Subsection \ref{subsec: initialization} shows the tasks that are used here as an example and the communication matrix to highlight which task is communicating with which one so that the cluster can be formed. Subsection \ref{subsec: cost calculation}, not only desribes step-by-step on how communication cost between cores are calculated, but also shows code snippet to present the actual implementation. Subsection \ref{subsec: Output} lists the terminal-based output that is received when running the code. Finally, \ref{subsec: simulation} shows a UPPAAL simulation of the


\subsection{Clustering}
\label{subsec: clustering}
\begin{algorithm}
\caption{Assign Clusters to Cores}
\begin{algorithmic}[1]
\FOR{each cluster in clusters}
    \STATE Find the least-loaded core that can still take the cluster’s total utilization
    \STATE Assign all tasks in the cluster to that core
    \STATE Update the core's utilization
\ENDFOR
\end{algorithmic}
\label{alg:cluster_assignment}
\end{algorithm}


\subsection{Task Initilization and Communication Volume}
\label{subsec: initialization}
7 tasks are initiliazed with their core properties, as already discussed: period and worst case execution time. As already states, utilization of core cannot exceed one for a new task to be allocated as shown in equation \ref{eq:utilization_constraint}. Table \ref{tab:task_parameters} show the tasks with their corresponding properties. 

\begin{table}[htbp]
\centering
\caption{Task Parameters}
\label{tab:task_parameters}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Task No.} & \textbf{Execution Time (C)} & \textbf{Period (T)} \\
\hline
0 & 1 & 5 \\
1 & 2 & 10 \\
2 & 1 & 4 \\
3 & 2 & 8 \\
4 & 3 & 4 \\
5 & 1 & 10 \\
6 & 5 & 6 \\
\hline
\end{tabular}
\end{table}

Table \ref{tab:task_dependency_matrix} shows the communication volume between tasks. It basically shows how much in bytes are being transferred as message from one task to another. The clustering logic checks if a task can be placed on a core that already has a communicating task and whether the resulting utilization stays under the maximum utilization threshold of 1.


\begin{table}[htbp]
\centering
\caption{Task Dependency Matrix}
\label{tab:task_dependency_matrix}
\setlength{\tabcolsep}{2pt} % Reduce column padding
\renewcommand{\arraystretch}{2} % Reduce row height
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
 & \textbf{T0} & \textbf{T1} & \textbf{T2} & \textbf{T3} & \textbf{T4} & \textbf{T5} & \textbf{T6} \\
\hline
\textbf{T0} & 0 & 5 & 3 & 9 & 0 & 0 & 0 \\
\textbf{T1} & 5 & 0 & 4 & 7 & 0 & 0 & 0 \\
\textbf{T2} & 3 & 4 & 0 & 0 & 0 & 0 & 0 \\
\textbf{T3} & 9 & 7 & 0 & 0 & 0 & 8 & 0 \\
\textbf{T4} & 0 & 0 & 0 & 0 & 0 & 0 & 7 \\
\textbf{T5} & 0 & 0 & 0 & 8 & 0 & 0 & 0 \\
\textbf{T6} & 0 & 0 & 0 & 0 & 7 & 0 & 0 \\
\hline
\end{tabular}
\end{table}


The points to notice are the following: Task 0,1,2 and 3 are in constant communication with each other. Therefore if the equation \ref{eq:utilization_constraint} allows, these tasks can be allocated in one core. In this case, the total utilization of these 4 tasks is equal to 0.9 leading to their allocation in Core 0. Task 5 on the other hand only is in communication with Task 3. Therefore the utilization of this task has to comply wth equation \ref{eq:utilization_constraint} for the core. As Task 5 only has 0.1 as utilization, the task was able to be allocated in Core 0 forming the cluster. Task 4 and 6 only communicate among each other. This leads to these two tasks forming a cluster. However, once Task 4 is allocated in Core 1, the utilization constrain does not allow Task 6 to be placed in Core 1. This leads to Task 6 being placed in the neighbouring core of Core 2. The allocation of Task 2 in a core near to Core 1 reduces the communication cost between Core 1 and Core 2.
 This is shown here in the terminal output:

\subsection{Cost calculation}
\label{subsec: cost calculation}
Equations \ref{eq:cost_function} and \ref{eq:total_cost} dicussed in subsection \ref{sec: clustering-based scheduling} are used to calculate the total communication cost between cores. 

The function \texttt{Calculating\_TotalCommunicationCost()} is responsible for computing the total communication cost incurred by the task-to-core mapping in a multi-core system. It begins by initializing a variable \texttt{totalCost} to zero. This variable accumulates the overall communication cost resulting from interactions between tasks assigned to different cores.

The function iterates over every possible pair of cores in the system using two nested loops. Let us denote the outer loop index as \texttt{firstCore} and the inner loop index as \texttt{secondCore}. For each core pair, it proceeds to examine all pairs of tasks, where one task belongs to \texttt{firstCore} and the other to \texttt{secondCore}. This is achieved through another two nested loops that traverse the list of assigned tasks for each core.

For each task pair, the function identifies two tasks: \texttt{firstTask} assigned to \texttt{firstCore} and \texttt{secondTask} assigned to \texttt{secondCore}. It then calculates the communication cost between these tasks by multiplying two quantities:
\begin{itemize}
    \item \texttt{communicationVolume[firstTask][secondTask]}, which represents the volume of data or messages exchanged between the tasks.
    \item \texttt{costMatrix[firstCore][secondCore]}, which captures the communication cost between the two cores themselves (often modeled as distance or latency).
\end{itemize}

The product of these two terms gives the cost of communication between the selected pair of tasks, considering both the data exchanged and the penalty associated with inter-core communication. This cost is added to the running total \texttt{totalCost}.

The function continues this process for all combinations of core pairs and their respective assigned tasks. After all relevant combinations have been evaluated, the function returns \texttt{totalCost}, which reflects the complete communication burden introduced by the current allocation of tasks to cores. This metric is critical for assessing the efficiency of clustering algorithms in minimizing communication overhead.

List \ref{lst:total_comm_cost} shows a code snippet of the implementation of calculating total communication cost. 

\begin{lstlisting}[caption={Function to calculate total communication cost}, label={lst:total_comm_cost}]
float Calculating_TotalCommunicationCost() {
    float totalCost = 0.0;

    for (int firstCore = 0; firstCore < numberOfCores; firstCore++) {
        for (int secondCore = 0; secondCore < numberOfCores; secondCore++) {

            for (int i = 0; i < cores[firstCore].num_tasks; i++) {
                for (int j = 0; j < cores[secondCore].num_tasks; j++) {

                    int firstTask = cores[firstCore].assigned_tasks[i];
                    int secondTask = cores[secondCore].assigned_tasks[j];

    totalCost += costMatrix[firstCore][secondCore] * 
                communicationVolume[firstTask][secondTask];
                }
            }
        }
    }

    return totalCost;
}
\end{lstlisting}
\subsection{Output}
\label{subsec: Output}
And finally, the output from the terminal is as follows, as already discussed from the implementation of total communication cost along with the clustering algorithm described in algorithm \ref{alg:cluster_assignment}. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{Allocation of Tasks on cores.png}
    \caption{Allocation of Tasks on cores}
    \label{fig:enter-label}
\end{figure}
%  \begin{lstlisting}
% myenvrubayetkamal@Rubayets-MacBook-Air Partition based scheduling on multi-core system % ./main                      
% Core 0 [Util: 1.00]: T0 T1 T2 T3 T5 
% Core 1 [Util: 0.75]: T4 
% Core 2 [Util: 0.83]: T6 
% Total Communication Cost: 33.00
% \end{lstlisting}

\subsection{Simulation}
\label{subsec: simulation}
Fig. \ref{fig:UPPAAL} shows the sequence of how the scheduler and the allocation algorithms are synchronized. EDF is not used in this simulation die to time limitation and level of complication of the system. Only the first core is simulated which waits for cores to be allocated once they pass the utilization test. After that, it is up to the scheduler to execute the task in a particular order. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{UPPAAL.png}
    \caption{UPPAAL}
    \label{fig:UPPAAL}
\end{figure}

\section{Conclusion}
\label{subsec: conclusion}
In this paper, partition-based scheduling of multi-core real-time systems is explored.  The problem of periodic tasks allocation on a homogeneous multi-core architecture using tasks clustering is discussed. The clustering-based scheduling algorithm, inspired from \cite{AbdallahGB24} is implemented in C and later simulated in UPPAAL. The output of the proposed solution shows tasks with frequent communication among each other form a cluster and they are allocated on cores close to each other to reduce communication cost, provided that all cores pass the schedulability test. 

\printbibliography

\end{document}
